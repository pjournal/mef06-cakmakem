{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Web Scraping and Clustering in Python\"\n",
        "author: \"Emre Ã‡akmak\"\n",
        "date: \"2022-10-20\"\n",
        "toc: true\n",
        "toc-location: left\n",
        "number-sections: true\n",
        "format: \n",
        "  html:\n",
        "    theme: \n",
        "      dark: vapor\n",
        "      light: pulse\n",
        "    fontsize: 0.8em\n",
        "editor: visual\n",
        "---"
      ],
      "id": "5e796f36"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Web Scraping and Clustering on NFT Marketplace\n",
        "\n",
        "We are importing the required libraries. Especially selenium for scraping, pandas for dataframes and sklearn for clustering processes.\n"
      ],
      "id": "14ffbd18"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import socket\n",
        " \n",
        "import io\n",
        "import shutil\n",
        "import re\n",
        "import urllib.request\n",
        "import os\n",
        "import errno\n",
        "\n",
        "import urllib.request\n",
        "import xlsxwriter\n",
        "import time\n",
        "\n",
        "import pandas\n",
        "import numpy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from kneed import KneeLocator\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "driver = webdriver.Chrome(r\"C:\\Users\\EMRE\\PycharmProjects\\chromedriver.exe\")\n",
        "driver.get(\"https://www.jpg.store/collection/pavia?minPrice=300000000&maxPrice=1000000000\")\n",
        "\n",
        "SCROLL_PAUSE_TIME = 0.8\n",
        "\n",
        "# Get scroll height\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "a=0\n",
        "n=5\n",
        "while a<n:\n",
        "    # Scroll down to bottom\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    # Wait to load page\n",
        "    time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "    # Calculate new scroll height and compare with last scroll height\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "        break\n",
        "    last_height = new_height\n",
        "    a+=1\n",
        "\n",
        "\n",
        "itemset = []\n",
        "priceset=[]\n",
        "content = driver.page_source\n",
        "soup = BeautifulSoup(content)\n",
        "for a in soup.find_all('div', attrs = {'class', 'styles_itemsGrid__J7c4P grid'}):\n",
        "    children = a.findChildren(\"span\", recursive=False)\n",
        "    for child in children:\n",
        "        sublings = child.find_all('div', attrs = {'class', 'NFTMarketplaceCard_nftMarketplaceCardContent__I5fdd'})\n",
        "        pricesclass = child.find_all('div', attrs = {'class', 'NFTMarketplaceCard_nftMarketplaceCardPriceContainer__a3CBp'})\n",
        "        for items in sublings:\n",
        "            a=items.findChildren(\"h4\",recursive=False)\n",
        "            #.find_all('h4', attrs = {'id', 'asset-title'})\n",
        "            #for i in a.contents:\n",
        "            itemset.append(a[0])\n",
        "        for price in pricesclass:\n",
        "            b=price.findChildren(\"div\", recursive=False)\n",
        "            for c in b:\n",
        "                d=c.findChildren(\"span\",recursive=False)\n",
        "                priceset.append(d[0])\n",
        "\n",
        "df = pd.DataFrame(itemset, columns=[\"names\"])\n",
        "df_p = pd.DataFrame(priceset, columns=['price'])\n",
        "\n",
        "df_final =  pd.concat([df,df_p],axis=1)\n",
        "\n",
        "## df_final.to_excel('20102022_2_nft.xlsx', encoding='utf-16',engine='xlsxwriter')\n",
        "\n",
        "\n",
        "df_final[['name','space','X','Y']]=df_final.names.str.split(' ',3,expand=True)\n",
        "df_final=df_final[['X','Y','price']]\n",
        "df_final=df_final[(df_final['X']!='-')&(df_final['Y']!='-')&(df_final['X']!='')&(df_final['Y']!='')&(df_final['X']!=' ')&(df_final['Y']!=' ')]\n",
        "\n",
        "df_final['X']=pd.to_numeric(df_final['X'],downcast='integer')\n",
        "df_final['Y']=pd.to_numeric(df_final['Y'],downcast='integer')\n",
        "\n",
        "df_final['distance_to_origin']=(abs((df_final['X'])**2 + (df_final['Y']**2)))**0.5\n",
        "\n",
        "kmeans_kwargs = {\n",
        "    \"init\": \"random\",\n",
        "    \"n_init\": 10,\n",
        "    \"max_iter\": 300,\n",
        "    \"random_state\": 42,\n",
        "}\n",
        "\n",
        "# # A list holds the SSE values for each k\n",
        "sse = []\n",
        "for k in range(1, 30):\n",
        "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
        "    kmeans.fit(df_final[['X','Y','distance_to_origin']])\n",
        "    sse.append(kmeans.inertia_)\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "plt.plot(range(1, 30), sse)\n",
        "plt.xticks(range(1, 30))\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "##print('specify number of clusters')\n",
        "##k=int(input())\n",
        "\n",
        "k=10\n",
        "kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
        "df_final['cluster']=kmeans.fit_predict(df_final[['X','Y','distance_to_origin']])\n",
        "df_final['cluster'] = df_final['cluster'].astype('category')\n",
        "\n",
        "\n",
        "results = df_final.groupby('cluster').agg({'price':['mean','std']})\n",
        "results=results.reset_index()\n",
        "results.columns=['cluster','mean','std']\n",
        "df_final=df_final.merge(results,left_on='cluster',right_on='cluster')\n",
        "df_final['low_limit']=df_final['mean']-1.5*df_final['std']\n",
        "df_final['d_p_rate'] = df_final['distance_to_origin']/df_final['price'].astype(float)\n",
        "\n",
        "results_dp = df_final.groupby('cluster').agg({'d_p_rate':['mean','std']})\n",
        "results_dp=results_dp.reset_index()\n",
        "results_dp.columns=['cluster','mean_dp','std_dp']\n",
        "df_final=df_final.merge(results_dp,left_on='cluster',right_on='cluster')\n",
        "\n",
        "df_final['low_limit_dp']=df_final['mean_dp']-1.5*df_final['std_dp']\n",
        "\n",
        "finalists=df_final[(df_final['price'].astype(float)<df_final['low_limit'])&(df_final['d_p_rate']<df_final['mean_dp'])]\n",
        "\n",
        "finalists[1:10]"
      ],
      "id": "4de1f88a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}