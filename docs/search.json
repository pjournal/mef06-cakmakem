[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emre Çakmak Progress Journal",
    "section": "",
    "text": "This progress journal covers Emre Çakmak’s work during their term at BDA 503 Fall 2022.\nEach section is an assignment or an individual work."
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "1  BDA-503 Assigment 1",
    "section": "",
    "text": "Hi dear reader,\nI’m Emre Çakmak from Istanbul/Turkey. I graduated from my bachelor at Istanbul Technical University, Industrial Engineering Department in 2018.\nMy current role is Data Scientist at E-commerce Department in LC Waikiki which is a Istanbul based global fashion retailer driving operations on more than 50 countries. I had different positions like Data Analyst, Business Intelligence Specialist in different companies during past 4 years. Especially in last 1 year, I dedicated to improve myself for application of ML Technics due to enrich customer&item based data. So, I’m a part of BDA Graduate Program in MEF University to wide my knowledge in audience management and marketing applications by the help of real-life use cases.\nHere is my LinkedIn Profile"
  },
  {
    "objectID": "assignment1.html#rstudio-global-2022-conference---quarto-for-the-curious",
    "href": "assignment1.html#rstudio-global-2022-conference---quarto-for-the-curious",
    "title": "1  BDA-503 Assigment 1",
    "section": "1.2 RStudio Global 2022 Conference - Quarto for the Curious",
    "text": "1.2 RStudio Global 2022 Conference - Quarto for the Curious\n\nWhat’s Quarto according to Tom Mock\nIn this paragraph, I aim to give you some main differences between Quarto, the brand new documentation system which has been released April 2022, and RMarkdown being used for almost a decade.\n\nTom Mock says Quarto is Open source scientific and technical publishing system. Also he added that Quarto is the next generation of RMarkdown.\n\nHere is some differences between them:\n\n1.2.1 Preprocessing\n\n\n\n\n\n\n\n(a) RMarkdown\n\n\n\n\n\n\n\n(b) Quarto\n\n\n\n\nFigure 1.1: RMarkdown vs Quarto Preprocessing Diagram\n\n\nAltough it seems like they have almost same workflow behind the scenes; Quarto doesn’t need to have R in the system to use it. It means that you can use Quarto in a fresh computer but Rmarkdown needs to have R in the system.\n\n\n1.2.2 Language Support\nThe main purpose of releasing Quarto is improving the communication between data science communities whatever their language is. Because of this Quarto supports other languages as engine.\n\n\n\nFigure 1.2: Jupyter as Quarto Engine\n\n\nThis availability in Quarto and not limiting with R allows people to collaborate as Python developer with others. Tom Mock figured this situation out like\n\nQuarto: Comfortable baking in your own kitchen\nRMarkdown: Uncomfortable baking in corporate kitchen"
  },
  {
    "objectID": "assignment1.html#r-posts",
    "href": "assignment1.html#r-posts",
    "title": "1  BDA-503 Assigment 1",
    "section": "1.3 R Posts",
    "text": "1.3 R Posts\nThis section includes 3 different R Programming use case\n\n1.3.1 Web Scraping with R\nIt’s very known fact that people have some struggle to access to a clean dataset. In these cases, we need to be a little bit creative to create our own dataset. And one way of the creating a new dataset is web scraping.\nIn this paragraph, I want to introduce how to scrape a web page by the help of R packages. The most common 2 packages are:\n\n{rvest}\n{RSelenium}\n\nNote that: Some websites have strict policies against scraping. Be careful!\nStep by step scraping of public IMDB Dataset\nStep 1: Install Package\n\n## Before you start, you need to execute once the code below.\n##install.packages(\"rvest\")\n\nStep 2: Call the library and use html functions\n\n## call the rvest library for required functions\nlibrary(rvest)\n\n## define the website link you want to scrape\nlink = \"https://www.imdb.com/search/title/?title_type=feature&num_votes=30000,&genres=comedy\"\n\n## send a http get request to the link above and store it in a variable\npage = read_html(link)\n\n## filter and grab all elements in same class\ntitles = page %>% html_nodes(\".lister-item-header a\") %>% html_text()\n\n## preview the titles\ntitles[1:10]\n\n [1] \"Hocus Pocus\"                       \"Bullet Train\"                     \n [3] \"Thor: Love and Thunder\"            \"DC League of Super-Pets\"          \n [5] \"Everything Everywhere All at Once\" \"Beetle Juice\"                     \n [7] \"Super Mario Bros.\"                 \"Trick 'r Treat\"                   \n [9] \"Once Upon a Time... in Hollywood\"  \"Knives Out\"                       \n\n\nStep 3: Create other variables\n\n## apply same procedure to other variables\nyear= page %>% html_nodes(\".text-muted.unbold\") %>% html_text()\nrating = page %>% html_nodes(\".ratings-imdb-rating strong\") %>% html_text()\n\n\n## preview variables\nyear[1:10]\n\n [1] \"(1993)\" \"(2022)\" \"(2022)\" \"(2022)\" \"(2022)\" \"(1988)\" \"(1993)\" \"(2007)\"\n [9] \"(2019)\" \"(2019)\"\n\nrating[1:10]\n\n [1] \"6.9\" \"7.4\" \"6.4\" \"7.4\" \"8.1\" \"7.5\" \"4.1\" \"6.7\" \"7.6\" \"7.9\"\n\n\nStep 4: Create data frame\n\n## create a dataset\nmovies = data.frame(titles, year, rating, stringsAsFactors = FALSE)\nmovies[1:10,]\n\n                              titles   year rating\n1                        Hocus Pocus (1993)    6.9\n2                       Bullet Train (2022)    7.4\n3             Thor: Love and Thunder (2022)    6.4\n4            DC League of Super-Pets (2022)    7.4\n5  Everything Everywhere All at Once (2022)    8.1\n6                       Beetle Juice (1988)    7.5\n7                  Super Mario Bros. (1993)    4.1\n8                     Trick 'r Treat (2007)    6.7\n9   Once Upon a Time... in Hollywood (2019)    7.6\n10                        Knives Out (2019)    7.9\n\n\nReferences of web scraping with R:\n\nScraperapi\nScrapingbee\nAppsilon\n\n\n\n1.3.2 Simple Aggregations on Dataset\nThis part provides some basic aggregations and data manipulation methods in R via {dplyr} package.\nWithout leaving the concept in previous part, we can assume that we created our own dataset. So, what’s next?\nThe process of extracting insightful information from datasets starts from understanding the data structure and manipulating them. R provides a package just for this: {dplyr}\nStep by step aggregation & filtering & summarizing dataset\nStep 1: Install Package\n\n## Before you start, you need to execute once the code below.\n##install.packages(\"dplyr\")\n\nStep 2: Call the library\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nStep 3: Select subset of data in different aspects\n\n## selecting specific columns\nselect(movies, titles, year)[1:10,]\n\n                              titles   year\n1                        Hocus Pocus (1993)\n2                       Bullet Train (2022)\n3             Thor: Love and Thunder (2022)\n4            DC League of Super-Pets (2022)\n5  Everything Everywhere All at Once (2022)\n6                       Beetle Juice (1988)\n7                  Super Mario Bros. (1993)\n8                     Trick 'r Treat (2007)\n9   Once Upon a Time... in Hollywood (2019)\n10                        Knives Out (2019)\n\n## filter data according to specific condition\nfilter(movies, rating > 8)\n\n                             titles   year rating\n1 Everything Everywhere All at Once (2022)    8.1\n2           The Wolf of Wall Street (2013)    8.2\n3                          Deadpool (2016)    8.0\n4                Back to the Future (1985)    8.5\n\n## sort rows\narrange(movies, desc(titles))[1:10,]\n\n                                    titles   year rating\n1                           Trick 'r Treat (2007)    6.7\n2                   Thor: Love and Thunder (2022)    6.4\n3                  The Wolf of Wall Street (2013)    8.2\n4                              The Witches (1990)    6.8\n5  The Unbearable Weight of Massive Talent (2022)    7.0\n6                        The Suicide Squad (2021)    7.2\n7            The Rocky Horror Picture Show (1975)    7.4\n8                            The Lost City (2022)    6.1\n9                            The Lost Boys (1987)    7.2\n10                             The Goonies (1985)    7.7\n\n## select top n rows\ntop_n(movies, 3, titles)\n\n                   titles   year rating\n1  Thor: Love and Thunder (2022)    6.4\n2          Trick 'r Treat (2007)    6.7\n3 The Wolf of Wall Street (2013)    8.2\n\n\nStep 4: Summarize Dataset\n\n## convert rating columns as numeric and calculate the average\nsummarise(movies, average_rating = mean(as.numeric(rating)))\n\n  average_rating\n1          6.882\n\n## group by and summarize\ngrouped_data = group_by(movies, year)\nsummarise(grouped_data, average_rating = mean(as.numeric(rating)))[1:5,]\n\n# A tibble: 5 × 2\n  year   average_rating\n  <chr>           <dbl>\n1 (1975)            7.4\n2 (1984)            7.8\n3 (1985)            8.1\n4 (1987)            7.2\n5 (1988)            7.5\n\n\nStep 5: %>% Operator\nThis operator takes the object from the left and gives it as the first argument to the function on the right. It makes your code more readable.\n\n## same grouping and summarizing operation at step4 \n\nmovies %>%\n  group_by(year) %>%\n  summarise(average_rating = mean(as.numeric(rating)))%>%\n  top_n(5, desc(average_rating))\n\n# A tibble: 7 × 2\n  year       average_rating\n  <chr>               <dbl>\n1 (1993)                5.5\n2 (1995)                6.5\n3 (2002)                5.2\n4 (2005)                6.5\n5 (2009)                5.3\n6 (2020)                5.2\n7 (I) (2022)            6.5\n\n\nReference of aggregations with R:\n\ncourses.cs.ut.ee\n\n\n\n1.3.3 Visualization with R\nStep 1: Install Package\n\n## Before you start, you need to execute once the code below.\n##install.packages(\"ggplot2\")\n\nStep 2: Call the library\n\nlibrary(ggplot2)\n\nStep 3: Histogram with ggplot2\n\n## convert rating field as numeric and keep in original dataset\nmovies$rating=as.numeric(rating)\n\n## histogram for ratings\nhist(movies$rating,col='steelblue',main='Rating Histogram',\n     xlab='Ratings')\n\n\n\n\nStep 4: Pie Chart with ggplot2\n\n## Set a new flag in dataset\nmovies=movies %>% mutate(rating_flag = case_when(rating>=8~ \"Higher 8\", TRUE ~ \"Lower 8\"))\n\n## creating a new table for better visualization\ncount_movies=movies %>% count(rating_flag)\n\n## pie chart according to rating of movies\nggplot(count_movies, aes(x = \"\", y = n, fill = rating_flag)) +\n  geom_col(color = \"black\") +\n  geom_label(aes(label = n),\n             position = position_stack(vjust = 0.5),\n             show.legend = FALSE) +\n  coord_polar(theta = \"y\")\n\n\n\n\nReferences of visualization with R:\n\nr-charts\nkdnuggets"
  }
]