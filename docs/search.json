[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emre Çakmak Progress Journal",
    "section": "",
    "text": "This progress journal covers Emre Çakmak’s work during their term at BDA 503 Fall 2022.\nEach section is an assignment or an individual work."
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "1  BDA-503 Assigment 1",
    "section": "",
    "text": "Hi dear reader,\nI’m Emre Çakmak from Istanbul/Turkey. I graduated from my bachelor at Istanbul Technical University, Industrial Engineering Department in 2018.\nMy current role is Data Scientist at E-commerce Department in LC Waikiki which is a Istanbul based global fashion retailer driving operations on more than 50 countries. I had different positions like Data Analyst, Business Intelligence Specialist in different companies during past 4 years. Especially in last 1 year, I dedicated to improve myself for application of ML Technics due to enrich customer&item based data. So, I’m a part of BDA Graduate Program in MEF University to wide my knowledge in audience management and marketing applications by the help of real-life use cases.\nHere is my LinkedIn Profile"
  },
  {
    "objectID": "assignment1.html#rstudio-global-2022-conference---quarto-for-the-curious",
    "href": "assignment1.html#rstudio-global-2022-conference---quarto-for-the-curious",
    "title": "1  BDA-503 Assigment 1",
    "section": "1.2 RStudio Global 2022 Conference - Quarto for the Curious",
    "text": "1.2 RStudio Global 2022 Conference - Quarto for the Curious\n\nWhat’s Quarto according to Tom Mock\nIn this paragraph, I aim to give you some main differences between Quarto, the brand new documentation system which has been released April 2022, and RMarkdown being used for almost a decade.\n\nTom Mock says Quarto is Open source scientific and technical publishing system. Also he added that Quarto is the next generation of RMarkdown.\n\nHere is some differences between them:\n\n1.2.1 Preprocessing\n\n\n\n\n\n\n\n(a) RMarkdown\n\n\n\n\n\n\n\n(b) Quarto\n\n\n\n\nFigure 1.1: RMarkdown vs Quarto Preprocessing Diagram\n\n\nAltough it seems like they have almost same workflow behind the scenes; Quarto doesn’t need to have R in the system to use it. It means that you can use Quarto in a fresh computer but Rmarkdown needs to have R in the system.\n\n\n1.2.2 Language Support\nThe main purpose of releasing Quarto is improving the communication between data science communities whatever their language is. Because of this Quarto supports other languages as engine.\n\n\n\nFigure 1.2: Jupyter as Quarto Engine\n\n\nThis availability in Quarto and not limiting with R allows people to collaborate as Python developer with others. Tom Mock figured this situation out like\n\nQuarto: Comfortable baking in your own kitchen\nRMarkdown: Uncomfortable baking in corporate kitchen"
  },
  {
    "objectID": "assignment1.html#r-posts",
    "href": "assignment1.html#r-posts",
    "title": "1  BDA-503 Assigment 1",
    "section": "1.3 R Posts",
    "text": "1.3 R Posts\nThis section includes 3 different R Programming use case\n\n1.3.1 Web Scraping with R\nIt’s very known fact that people have some struggle to access to a clean dataset. In these cases, we need to be a little bit creative to create our own dataset. And one way of the creating a new dataset is web scraping.\nIn this paragraph, I want to introduce how to scrape a web page by the help of R packages. The most common 2 packages are:\n\n{rvest}\n{RSelenium}\n\nNote that: Some websites have strict policies against scraping. Be careful!\nStep by step scraping of public IMDB Dataset\nStep 1: Install Package\n\n## Before you start, you need to execute once the code below.\n##install.packages(\"rvest\")\n\nStep 2: Call the library and use html functions\n\n## call the rvest library for required functions\nlibrary(rvest)\n\n## define the website link you want to scrape\nlink = \"https://www.imdb.com/search/title/?title_type=feature&num_votes=30000,&genres=comedy\"\n\n## send a http get request to the link above and store it in a variable\npage = read_html(link)\n\n## filter and grab all elements in same class\ntitles = page %>% html_nodes(\".lister-item-header a\") %>% html_text()\n\n## preview the titles\ntitles[1:10]\n\n [1] \"Bullet Train\"                         \n [2] \"The Banshees of Inisherin\"            \n [3] \"Amsterdam\"                            \n [4] \"The Menu\"                             \n [5] \"Love Actually\"                        \n [6] \"National Lampoon's Christmas Vacation\"\n [7] \"A Christmas Story\"                    \n [8] \"Home Alone\"                           \n [9] \"The Addams Family\"                    \n[10] \"Triangle of Sadness\"                  \n\n\nStep 3: Create other variables\n\n## apply same procedure to other variables\nyear= page %>% html_nodes(\".text-muted.unbold\") %>% html_text()\nrating = page %>% html_nodes(\".ratings-imdb-rating strong\") %>% html_text()\n\n\n## preview variables\nyear[1:10]\n\n [1] \"(2022)\" \"(2022)\" \"(2022)\" \"(2022)\" \"(2003)\" \"(1989)\" \"(1983)\" \"(1990)\"\n [9] \"(1991)\" \"(2022)\"\n\nrating[1:10]\n\n [1] \"7.3\" \"8.0\" \"6.1\" \"7.5\" \"7.6\" \"7.5\" \"7.9\" \"7.7\" \"6.9\" \"7.6\"\n\n\nStep 4: Create data frame\n\n## create a dataset\nmovies = data.frame(titles, year, rating, stringsAsFactors = FALSE)\nmovies[1:10,]\n\n                                  titles   year rating\n1                           Bullet Train (2022)    7.3\n2              The Banshees of Inisherin (2022)    8.0\n3                              Amsterdam (2022)    6.1\n4                               The Menu (2022)    7.5\n5                          Love Actually (2003)    7.6\n6  National Lampoon's Christmas Vacation (1989)    7.5\n7                      A Christmas Story (1983)    7.9\n8                             Home Alone (1990)    7.7\n9                      The Addams Family (1991)    6.9\n10                   Triangle of Sadness (2022)    7.6\n\n\nReferences of web scraping with R:\n\nScraperapi\nScrapingbee\nAppsilon\n\n\n\n1.3.2 Simple Aggregations on Dataset\nThis part provides some basic aggregations and data manipulation methods in R via {dplyr} package.\nWithout leaving the concept in previous part, we can assume that we created our own dataset. So, what’s next?\nThe process of extracting insightful information from datasets starts from understanding the data structure and manipulating them. R provides a package just for this: {dplyr}\nStep by step aggregation & filtering & summarizing dataset\nStep 1: Install Package\n\n## Before you start, you need to execute once the code below.\n##install.packages(\"dplyr\")\n\nStep 2: Call the library\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nStep 3: Select subset of data in different aspects\n\n## selecting specific columns\nselect(movies, titles, year)[1:10,]\n\n                                  titles   year\n1                           Bullet Train (2022)\n2              The Banshees of Inisherin (2022)\n3                              Amsterdam (2022)\n4                               The Menu (2022)\n5                          Love Actually (2003)\n6  National Lampoon's Christmas Vacation (1989)\n7                      A Christmas Story (1983)\n8                             Home Alone (1990)\n9                      The Addams Family (1991)\n10                   Triangle of Sadness (2022)\n\n## filter data according to specific condition\nfilter(movies, rating > 8)\n\n                             titles   year rating\n1         The Banshees of Inisherin (2022)    8.0\n2 Everything Everywhere All at Once (2022)    8.1\n3                             Klaus (2019)    8.1\n4 Spider-Man: Into the Spider-Verse (2018)    8.4\n5           The Wolf of Wall Street (2013)    8.2\n6           Guardians of the Galaxy (2014)    8.0\n\n## sort rows\narrange(movies, desc(titles))[1:10,]\n\n                                  titles   year rating\n1                              Zoolander (2001)    6.5\n2                        White Christmas (1954)    7.5\n3                    Triangle of Sadness (2022)    7.6\n4                     Ticket to Paradise (2022)    6.2\n5                 Thor: Love and Thunder (2022)    6.3\n6                The Wolf of Wall Street (2013)    8.2\n7  The Santa Clause 3: The Escape Clause (2006)    4.8\n8                     The Santa Clause 2 (2002)    5.7\n9                       The Santa Clause (1994)    6.5\n10                     The Polar Express (2004)    6.6\n\n## select top n rows\ntop_n(movies, 3, titles)\n\n               titles   year rating\n1 Triangle of Sadness (2022)    7.6\n2     White Christmas (1954)    7.5\n3           Zoolander (2001)    6.5\n\n\nStep 4: Summarize Dataset\n\n## convert rating columns as numeric and calculate the average\nsummarise(movies, average_rating = mean(as.numeric(rating)))\n\n  average_rating\n1          6.868\n\n## group by and summarize\ngrouped_data = group_by(movies, year)\nsummarise(grouped_data, average_rating = mean(as.numeric(rating)))[1:5,]\n\n# A tibble: 5 × 2\n  year   average_rating\n  <chr>           <dbl>\n1 (1947)            7.9\n2 (1954)            7.5\n3 (1983)            7.6\n4 (1984)            7.3\n5 (1988)            6.9\n\n\nStep 5: %>% Operator\nThis operator takes the object from the left and gives it as the first argument to the function on the right. It makes your code more readable.\n\n## same grouping and summarizing operation at step4 \n\nmovies %>%\n  group_by(year) %>%\n  summarise(average_rating = mean(as.numeric(rating)))%>%\n  top_n(5, desc(average_rating))\n\n# A tibble: 5 × 2\n  year   average_rating\n  <chr>           <dbl>\n1 (1996)            5.7\n2 (2002)            5.7\n3 (2008)            5.7\n4 (2017)            5.6\n5 (2020)            5.8\n\n\nReference of aggregations with R:\n\ncourses.cs.ut.ee\n\n\n\n1.3.3 Visualization with R\nStep 1: Install Package\n\n## Before you start, you need to execute once the code below.\n##install.packages(\"ggplot2\")\n\nStep 2: Call the library\n\nlibrary(ggplot2)\n\nStep 3: Histogram with ggplot2\n\n## convert rating field as numeric and keep in original dataset\nmovies$rating=as.numeric(rating)\n\n## histogram for ratings\nhist(movies$rating,col='steelblue',main='Rating Histogram',\n     xlab='Ratings')\n\n\n\n\nStep 4: Pie Chart with ggplot2\n\n## Set a new flag in dataset\nmovies=movies %>% mutate(rating_flag = case_when(rating>=8~ \"Higher 8\", TRUE ~ \"Lower 8\"))\n\n## creating a new table for better visualization\ncount_movies=movies %>% count(rating_flag)\n\n## pie chart according to rating of movies\nggplot(count_movies, aes(x = \"\", y = n, fill = rating_flag)) +\n  geom_col(color = \"black\") +\n  geom_label(aes(label = n),\n             position = position_stack(vjust = 0.5),\n             show.legend = FALSE) +\n  coord_polar(theta = \"y\")\n\n\n\n\nReferences of visualization with R:\n\nr-charts\nkdnuggets"
  },
  {
    "objectID": "inclass1.html",
    "href": "inclass1.html",
    "title": "2  Inclass Exercise-1",
    "section": "",
    "text": "This exercise has been prepared for understanding {dplyr} package usage for functional EDA. Main data set in this exercise will be planes data set derived from FAA.\nFirst of all we have to install our packages.\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"nycflights13\")\n\nThen we are calling our libraries.\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\nLet’s check first 10 rows of the data set. Fields and their meanings are:\n\ntailnum: Tail number.\nyear: Year manufactured.\ntype: Type of plane.\nmanufacturer: Manufacturer of the aircraft.\nmodel: Model of the aircraft.\nengines: Number of engines\nseats: Number of seats\nspeed: Average cruising speed in mph.\nengine: Type of engine.\n\n\nplanes %>% \n  slice(1:10)\n\n# A tibble: 10 × 9\n   tailnum  year type                   manuf…¹ model engines seats speed engine\n   <chr>   <int> <chr>                  <chr>   <chr>   <int> <int> <int> <chr> \n 1 N10156   2004 Fixed wing multi engi… EMBRAER EMB-…       2    55    NA Turbo…\n 2 N102UW   1998 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n 3 N103US   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n 4 N104UW   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n 5 N10575   2002 Fixed wing multi engi… EMBRAER EMB-…       2    55    NA Turbo…\n 6 N105UW   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n 7 N107US   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n 8 N108UW   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n 9 N109UW   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n10 N110UW   1999 Fixed wing multi engi… AIRBUS… A320…       2   182    NA Turbo…\n# … with abbreviated variable name ¹​manufacturer"
  },
  {
    "objectID": "inclass1.html#exercise-1",
    "href": "inclass1.html#exercise-1",
    "title": "2  Inclass Exercise-1",
    "section": "2.1 EXERCISE 1",
    "text": "2.1 EXERCISE 1\nNow, how many aircraft does exists for each manufacturing company? Let’s calculate..\n\nplanes %>% \n  group_by(manufacturer) %>% \n  summarise(aircraft_count = n()) %>% \n  arrange(desc(aircraft_count)) %>% \n  print(n=Inf)\n\n# A tibble: 35 × 2\n   manufacturer                  aircraft_count\n   <chr>                                  <int>\n 1 BOEING                                  1630\n 2 AIRBUS INDUSTRIE                         400\n 3 BOMBARDIER INC                           368\n 4 AIRBUS                                   336\n 5 EMBRAER                                  299\n 6 MCDONNELL DOUGLAS                        120\n 7 MCDONNELL DOUGLAS AIRCRAFT CO            103\n 8 MCDONNELL DOUGLAS CORPORATION             14\n 9 CANADAIR                                   9\n10 CESSNA                                     9\n11 PIPER                                      5\n12 AMERICAN AIRCRAFT INC                      2\n13 BEECH                                      2\n14 BELL                                       2\n15 GULFSTREAM AEROSPACE                       2\n16 STEWART MACO                               2\n17 AGUSTA SPA                                 1\n18 AVIAT AIRCRAFT INC                         1\n19 AVIONS MARCEL DASSAULT                     1\n20 BARKER JACK L                              1\n21 CANADAIR LTD                               1\n22 CIRRUS DESIGN CORP                         1\n23 DEHAVILLAND                                1\n24 DOUGLAS                                    1\n25 FRIEDEMANN JON                             1\n26 HURLEY JAMES LARRY                         1\n27 JOHN G HESS                                1\n28 KILDALL GARY                               1\n29 LAMBERT RICHARD                            1\n30 LEARJET INC                                1\n31 LEBLANC GLENN T                            1\n32 MARZ BARRY                                 1\n33 PAIR MIKE E                                1\n34 ROBINSON HELICOPTER CO                     1\n35 SIKORSKY                                   1\n\n\nIt seems like there is a conflict in manufacturer names. Some of them represent the same company but in different names like Airbus and Airbus Industrie.\nWe need to clean and rewrite these names. Then we can apply same process again.\n\nplanes =\nplanes %>% \n  mutate(manufacturer = gsub(\"AIRBUS INDUSTRIE\", \"AIRBUS\", manufacturer), manufacturer=gsub(\" AIRCRAFT CO| CORPORATION\", \"\", manufacturer))\n\nThe last version of distribution of air crafts according to their manufacturer is here.\n\nplanes %>% \n  group_by(manufacturer) %>% \n  summarise(aircraft_count = n()) %>% \n  arrange(desc(aircraft_count)) %>% \n  mutate(aircraft_count_distrubiton=round(aircraft_count/sum(aircraft_count),2)) %>% \n  print(n=Inf)\n\n# A tibble: 32 × 3\n   manufacturer           aircraft_count aircraft_count_distrubiton\n   <chr>                           <int>                      <dbl>\n 1 BOEING                           1630                       0.49\n 2 AIRBUS                            736                       0.22\n 3 BOMBARDIER INC                    368                       0.11\n 4 EMBRAER                           299                       0.09\n 5 MCDONNELL DOUGLAS                 237                       0.07\n 6 CANADAIR                            9                       0   \n 7 CESSNA                              9                       0   \n 8 PIPER                               5                       0   \n 9 AMERICAN AIRCRAFT INC               2                       0   \n10 BEECH                               2                       0   \n11 BELL                                2                       0   \n12 GULFSTREAM AEROSPACE                2                       0   \n13 STEWART MACO                        2                       0   \n14 AGUSTA SPA                          1                       0   \n15 AVIAT AIRCRAFT INC                  1                       0   \n16 AVIONS MARCEL DASSAULT              1                       0   \n17 BARKER JACK L                       1                       0   \n18 CANADAIR LTD                        1                       0   \n19 CIRRUS DESIGN CORP                  1                       0   \n20 DEHAVILLAND                         1                       0   \n21 DOUGLAS                             1                       0   \n22 FRIEDEMANN JON                      1                       0   \n23 HURLEY JAMES LARRY                  1                       0   \n24 JOHN G HESS                         1                       0   \n25 KILDALL GARY                        1                       0   \n26 LAMBERT RICHARD                     1                       0   \n27 LEARJET INC                         1                       0   \n28 LEBLANC GLENN T                     1                       0   \n29 MARZ BARRY                          1                       0   \n30 PAIR MIKE E                         1                       0   \n31 ROBINSON HELICOPTER CO              1                       0   \n32 SIKORSKY                            1                       0"
  },
  {
    "objectID": "inclass1.html#exercise-2",
    "href": "inclass1.html#exercise-2",
    "title": "2  Inclass Exercise-1",
    "section": "2.2 EXERCISE 2",
    "text": "2.2 EXERCISE 2\nLet’s check the difference on aircraft capacities year by year\nFirst, get only air crafts which have more than 50 seats. Then clear the data by filtering rows which have no information in Year column.\n\nplanes %>% \n  filter(seats>50,!is.na(year))%>%\n  group_by(year) %>% \n  summarise(seat_avg = round(mean(seats),2)) %>% \n  arrange(year) %>% \n  print(n=Inf)\n\n# A tibble: 38 × 2\n    year seat_avg\n   <int>    <dbl>\n 1  1956     102 \n 2  1965     149 \n 3  1975     139 \n 4  1976     139 \n 5  1977     139 \n 6  1978     139 \n 7  1979     139 \n 8  1980     139 \n 9  1984     178 \n10  1985     174.\n11  1986     196.\n12  1987     181.\n13  1988     190.\n14  1989     163.\n15  1990     179.\n16  1991     181.\n17  1992     195.\n18  1993     198.\n19  1994     178.\n20  1995     187.\n21  1996     170.\n22  1997     179.\n23  1998     169.\n24  1999     167.\n25  2000     163.\n26  2001     152.\n27  2002     132.\n28  2003     106.\n29  2004     116.\n30  2005     117.\n31  2006     141.\n32  2007     140.\n33  2008     147.\n34  2009     194.\n35  2010     164.\n36  2011     214.\n37  2012     207.\n38  2013     206.\n\n\nLet’s check the biggest air craft in our database with it’s tailnumber.\n\nplanes %>%\n  arrange(desc(seats)) %>% \n  slice(1) %>%\n  select(tailnum, manufacturer, model, year, seats)\n\n# A tibble: 1 × 5\n  tailnum manufacturer model    year seats\n  <chr>   <chr>        <chr>   <int> <int>\n1 N670US  BOEING       747-451  1990   450\n\n\nExciting..Here is some information about the biggest airplane’s history\nTHANKS FOR READING"
  },
  {
    "objectID": "shiny.html",
    "href": "shiny.html",
    "title": "3  BDA-503 Shiny Assignment",
    "section": "",
    "text": "3.0.2 shinyapps.io\nForeign Students Shiny App\n\n\n3.0.3 Command for local running\nshiny::runGitHub(“/pjournal/mef06-cakmakem”,subdir=“emre_cakmak_assigment/”, ref = “gh-pages”)"
  },
  {
    "objectID": "operation_research.html",
    "href": "operation_research.html",
    "title": "4  Operation Research Case Study",
    "section": "",
    "text": "This documentation aims to summarise real-life business problem which has been handled by operation research technics. You can find a short brief of a case study in e-commerce business in terms of the problem definition, problem complexity, previous and current situations and the results of the study. Happy readings..\nHere you can find the case study."
  },
  {
    "objectID": "operation_research.html#business-case",
    "href": "operation_research.html#business-case",
    "title": "4  Operation Research Case Study",
    "section": "4.2 Business Case",
    "text": "4.2 Business Case\nThe business case belongs to Emesa Co. which owns and operates a portfolio of leading online consumer auction and deal platforms in the Netherlands and Belgium.\nIt’s known fact that e-commerce businesses need to bring more customers to their websites or mobile applications to increase customer interactions with their products. By the help of increasing traffic, they expect to get more transaction and naturally more revenue. To achieve this goal, they have to use different methods to be in contact with their customers, one of these methods is E-mail marketing.\nEmesa company uses the e-mail marketing frequently for cost and customization advantages. But they are struggling with 2 major constrains.\n\nTiming: When should send the emails to customers?\nCustomization: Which content is best fit for which customer?\n\nThey was operating their email marketing campaigns manually and it was taking a lot of time and generating not quite efficient results. So, they decided to get some help from Gurabi Optimization which provides OR solutions."
  },
  {
    "objectID": "operation_research.html#time-for-optimization-and-implementation",
    "href": "operation_research.html#time-for-optimization-and-implementation",
    "title": "4  Operation Research Case Study",
    "section": "4.3 Time for Optimization and Implementation",
    "text": "4.3 Time for Optimization and Implementation\nAt the first glance, Emesa was a good opportunity; they can provide their constraints i.e. auction schedules and their customer preferences. But it was still a complex problem because of customer & email volume.\nThey started to build mathematical modeling with Gurobi to be able to automatically decide to send which email to which customer on which day.\n\nThey used auction bid histories to create customized email context which includes customer’s interests.\nCustomers email sending and opening history has been used for determining customer based email frequency. They found a solution to the question of how many email she/he does desire to see in weekly basis.\nThey build their mathematical model according to dynamic auction schedules.\nOR solution help them to easily avoid goverment’s regularizations."
  },
  {
    "objectID": "operation_research.html#what-are-the-results",
    "href": "operation_research.html#what-are-the-results",
    "title": "4  Operation Research Case Study",
    "section": "4.4 What are the results?",
    "text": "4.4 What are the results?\nBy the help of Gurobi,\n\nEmesa increased their email sent volume by 5%. Because there is no decision time for now. Everything is automatic.\nThey have 6% more opened emails than usual. Nothing could be do it except an OR solution.\nThese incrementations helped to conversion of customers. They got 6% more revenue from email campaigns anymore.\n\n\n\n\n\n\nThanks for reading.."
  }
]